\section{background}
\subsection{\acrlong{frp}}
\acrshort{frp} is a programming paradigm, where signal is the primary type. Signal can be define defined in Haskell as polymorphic type, which in as shown in listing \ref{lst:signalDef}. 
\begin{figure}
    \begin{hscode}
     type Signal a = Double -> a
    \end{hscode}
    \caption{Type definition of a signal in Haskell.}
    \label{lst:signalDef}
\end{figure}
Here are some examples of things that are often modelled with signal in FRP, and what their return type \verb|a| is.
\begin{enumerate}
    \item Animations are pictures that vary with time, to run an animation is supply a signal with the time (usually every 25'th second) and display the returned picture.
    \item User inputs, can be represented as signal that tells which buttons are pressed, by these in a collection of button Ids. 
    \item Sensor readings some of which can be user inputs, but input from physical measurements such as a pressure sensor, can also be thought as a signal from time to some amount of Pascal
    \item Prices on everything from bitcoins to bacon slices, is representable as signals from time to some currency of interest.
\end{enumerate}
A signal is therefore a function, which takes some positive time difference an returns a value of type \verb|a|. If for example \verb|a| is the type of a sensor measurement, then the corresponding signal is a function that takes time passed since the last time step at $t_0$ and returns the sensor measurement at $t = t_0 + \Delta t$.
Thus a Signal represents a time-varying value. However, for real-time systems signals raises issues, with both past and future values.
The past value concern is that the system is prone to space leaks, if the signal function should be able to return all possible measurements until now. 
For future values the concern is, that we do not know the measurement in the future, but there is nothing preventing time arguments where $t_0 + \Delta t > t_{now}$. The future value concern raises issues with causality, namely that some value now might depend on a value, that is not available yet.

\par Arrowised \acrshort{frp} deals these two concerns, by not having signal as first-class entities but rather uses so called Monadic Stream Functions as their representatives, which basically makes the signal functions themselves inaccessible. This approach protects from improper use, but working through such a representative can be quite cumbersome which can be appreciated by looking at some basic code snippets from Yampa\parencite{runtimeVerification}\ref{lst:yampaSnipppets}.
\begin{figure}
    \centering
    \begin{hscode}
        -- Type definition of Signal Function
        data SF a b = SF (DTime -> a -> (b, SF a b)) 
        -- Type definition of the Monadic Stream Function
        newtype MSF m a b
        -- Function to get a value of type b. 
        step :: Monad m => MSF m a b -> a -> m (b, MSF m a b)
    \end{hscode}
    \caption{Examples displaying complexity of MSF \parencite{runtimeVerification}}
    \label{lst:yampaSnipppets}
\end{figure}
To be fair, because Monadics Stream Function are instances of Arrow, their exists combinators and special notation\parencite{paterson}, that alleviates this problem, but there will be complexity under the hood, that enevitable will show up in development. 

\par A way to deal with this complexity, is to reallow the developer to work with signals directly, while mitigating prior concerns by the use of a modal type operator \verb|O|, and a type system that enforces the correct use of such, for an example consider the naive and protected implementation and use of a discrete signal function in listing, which can produces a polymorphic value denoted by the type variable \verb|a|.\ref{lst:modalExample}
\begin{figure}
    \centering
    \begin{hscode}
      -- definition
      data Str a = a ::: Str a
      currentVal (h ::: _) = h
      -- should be impossible for real-time systems.
      futureVal (h ::: strTail) = currentVal strTail  
      
      -- Rattus' definition
      data Str a = a ::: O (Str a)
      currentVal (h ::: _) = h
      -- Raise a type error in Haskell
      futureVal (h ::: delayedStrTail) = currentVal delayedStrTail  
      -- Compiles in Haskell but raises a type error in Rattus.
      futureVal' (h ::: delayedStrTail) = currentVal (adv delayedStrTail)  
      
    \end{hscode}
    \caption{Example displaying usage og the modal type operator.}
    \label{lst:modalExample}
\end{figure}
The \verb|futureVal| type error can mitigated since the exists a function \verb|adv :: O a -> a| which will convert the delayed stream to regular stream, but the compiler from Rattus, restricting the use adv. The general principle of these restrictions\parencite{KrishanType} is one of causality and is quite simple: It is allowed to use a delayed value, only in expressions whose value will be computed in a later time step.
\verb|futureVal'| fails to follow this principle, because it tries to acquire a value in a later time step now. 
\par Unfortunately the principle raises a question, how do we then tell the Rattus compiler that an expression is to be computed in the next time step? The answer is the semantic inverse of \verb|adv| and has the according type \verb|delay :: a -> O a|, to appreciate how they work together consider the following function, which maps every element of the input to the output stream using with f.
\begin{hscode}
    map :: Box (a -> b) -> Str a -> Str b 
    map f (h ::: t) = unbox f h ::: delay (map f (adv t)) 
\end{hscode}
Here \verb|adv| is used inside the expression whose value will be passed on to \verb|delay|, and thereby the causality principle. \verb|map| also uses another the box modality, which marks the inner function as one that safe to use inside delay, because of its time-independency. 
In practice the Rattus compiler is active on functions or modules using Haskell's compiler directives.
There are more things to the type system of Rattus, one which is how it prevents space-leaks, but going into details of such is beyond the scope of this project. Actually we will deliberately not activate the Rattus compiler, because we generate streams for testing rather receiving them in real-time. 




\subsection{\acrlong{pbt}}
\par If you see the semantics of a functions as something that takes an input, and then returns an output, then your natural way to test it would be to define an input, and somehow check, that the output is what you expected. That the approach taken in unit testing.
A different approach comes, when you look deeper into what the function actually models, and through that lens think about what properties that should for the output.

Take for example the measurement truck, for function \verb|fDist| that returns a distance from a laser to the road, we expect that the output is never negative, or larger than the height of the truck. We would expect that a function \verb|fAvg| making an average of two GPS's will always return a point between those.
If you were to make unittests you would probably check that all the following variables hold true:
\begin{figure}
    \begin{hscode}
        tDist1 = fDist 0 > 0 && fDist 0 < truckHeight
        tDist2 = fDist 1 > 0 && fDist 1 < truckHeight
        tDist3 = fDist (-1) > 0 && fDist (-1) < truckHeight
        -- etc. 
        tAvg0 = fAvg (1,0) (0,0) == (weight1, 0)
        tAvg1 = isBetween (0,0) (0,1) \$ fAvg (0,0) (0,1) 
        tAvg2 = not \$ isBetween (0,0) (0,0) \$ fAvg (0,0) (0,1) 
        tAvg3 = isBetween (0,0) (1,0) \$ fAvg (1,0) (0,0)
        -- etc.    
    \end{hscode}
        \caption{Caption}
    \label{lst:unitTests}
\end{figure}
This leads to large amount of time spent producing arbitrary test cases. In some cases the actual test cases might be good and covering, however this is rarely the case for blackbox-testing, and eitherway there will inevitably be noise in the quality such unit tests.
Properties are also closely related to models of problem domain. For instance the property stated in the example, resembles a verbal description of an average much better than all the test cases, despite that fact tests in general is already considered to increase comprehensibility of codebases.

\par When asserting a property the ideal would be to check that the property holds for all combinations of inputs, libraries such as SmallCheck does this. However this is only feasible when the size of the function-domain is very small. As the number of input cases is $O(2^n)$ where $n$ is the input size in bits. 
So instead of generating values covering the entire function-domain, the goal is to use random generator that picks values from a distribution, such that all possible execution paths are hit. Knowing exactly which distribution to pick from is a science in itself, however you can go a long way by treating each input as isolated, and let the generator only depend on the type. Consider a for example a function that returns a number that is 10 larger the highest of its 3 arguments, a simple property based approach is to generate 3 random numbers for inputs and test the property that these inputs are always lower than the all of the arguments.

\subsubsection{QuickCheck}
Having defined what properties are and a strategy for asserting them we need an actual implementation for testing them. Many programming languages has one or more tools for performing \acrshort{pbt}, examples are FastCheck for JavaScript, FsCheck for F\# and JUnit-QuickCheck for Java, they differ in implementation. But they are all inspired from the grandfather of \acrshort{pbt} QuickCheck\parencite{quickCheck}. Since QuickCheck is written and applicable for Haskell, it can take advantage of its typing system and pureness.
The pureness is a guarantee that the output of a function only depends on the input, this increases the reliability of the tests. The typing system for Haskell will come in handy generating test cases, to appreciate this consider the following compiling code given that isBetween is defined.
\begin{hscode}
    fAvg (x1, y1) (x2, y2) = ((x1 + x2) / 2, (y1 + y2) / 2)
    quickCheck (\ p1 p2 -> isBetween p1 p2 \$ fAvg p1 p2) 
    >>> Passed 100 tests
\end{hscode}
So here the property is expressed as the lambda passed on to quickCheck. The type of p1 and p2 is inferred, from the function declaration to have type Num, but to illustrate how this works, I expand the expression a bit more, and add some type declaration.
\begin{figure}[H]
\begin{hscode}
    prop_pointsAreBetween :: (Num, Num) -> (Num, Num) -> Property
    prop_pointsAreBetween p1 p2 = isBetween p1 p2 \$ fAvg p1 p2

    IO () 
    quickCheck prop_pointsAreBetween 
    >>> Passed 100 tests
\end{hscode}
\label{lst:qcExample}
\end{figure}
A property in QuickCheck is implemented as the type \verb|Property| which at its simplest, is just a definition of type bool, all of expressions in \ref{lst:unitTests} could be used as this type of Properties. The data for the 100 inputs were generated based the parameter types for \verb|prop_pointsAreBetween|. The default behavior is that values are generated using the \verb|arbitrary :: Gen a| function. Generating random values within a Haskell function would break its pureness. QuickChecks solves this problem by making \verb|Gen| an instance of \verb|Monad|.

\subsubsection{Gen Monad}
Since Gen is a Monad, along with many other types it is worthwhile to step back and go through what a Monad is. Monad is a typeclass defined as
\begin{hscode}
    class Applicative m => Monad m where
        return :: a -> m a
        (>>=) :: m a -> (a -> m b) -> m b 
        -- methods excluded for brevity
\end{hscode}
Monad models types that has both a context \verb|m|, which is \verb|Applicative|, and a polymorphic value. There are two core methods of our concern. 
\verb|return| takes a value and wraps it in a minimum context. In the case of Gen return \verb|a| is just a generator for values of type \verb|a|.
\verb|(>>=)| is also called bind. Bind returns the result of applying the second argument to the value first monad. Note that while the typeclass definition defines and interface, the implementation of, return, bind and methods from Applicative is left for the programmer. There also exists Monad laws such as associativity, but these are not checked by the compiler. 
A practical way to use Monads in Haskell is with the do-notation, which is syntactic sugar for bind-expressions nested in others. You can appreciate the do-notation by considering how you would implement a generator for complex numbers \verb|Z|. Such an implementation is done in listing \ref{lst:genComplex} using both \verb|return| and \verb|>>=|, and the do-notation.
\begin{figure}
    \begin{hscode}
    data Z = Z {a::Float, b::Float}
    genComplex = arbitrary >>= (\a -> arbitrary >>= (\b -> return Z {a=a, b=b}))
    genComplex' = do 
        a <- arbitrary
        b <- arbitrary
        return Z {a=a, b=b}
    \end{hscode} 
    \caption{Constructing a custom Gen monad with and without do-notation.}
    \label{lst:genComplex}
\end{figure}

I have already given example of how to make \verb|Gen Z|. Here I will elaborate a bit more on why that works, and how it can indeed generate random inputs in a pure functional programming language.
Consider the following hypothetical impure haskell function.
\begin{hscode}
    rollDice :: Int -> [Int]
    rollDice nSides = 
         randomInt 1 nSides
\end{hscode}
This function would return different results for identical inputs, which, is not pure. But suppose that \verb|rollDice| was called from \verb|main|, where IO is handled, if needed we could just get a list of randombits from IO and make randomInt that read from it.
\begin{figure}
    \centering
    \begin{hscode}
    rollDice ::(Int, [Bool]) -> Int
    rollDice (nSides, randombits) = 
         randomInt randombits 1 nSides
    \end{hscode}
    \caption{Fixing with random bits}
    \label{lst:randombitsFix}
\end{figure}

But the implementation in listing \ref{lst:randombitsFix} would only produce identical random numbers, such as 1,1,1,1 and so forth if called multiple times. To solve the issue we need to return from randomInt, information on which part randombits is already used, perhaps by returning a tuple \verb|(aRandomInt, unusedBitList)|. The type signature gets rather messy, we can prevent the by instead of returning the actual value could just produce a generator for the sought value, which could then be called where a random generator is actually available and its sequence of random values can advanced. Listing \ref{lst:GenDef} shows the relevant types for doing just that. 
\begin{figure}
    \centering
    \begin{hscode}
    newtype Gen a = MkGen {
        unGen :: QCGen -> Int -> a
    }
    generate :: Gen a -> IO a
    
    -- usage example in ghci
    > diceRoller :: Int -> Gen Int
    > diceRoller nSides = do 
        i <- (arbitrary:: Gen Int) 
        return (i `mod` nSides + 1)
    > generate (diceRoller 6)
    3
    > generate (diceRoller 6)
    6
    \end{hscode}
    \caption{Minimum example of Gen usage}
    \label{lst:GenDef}
\end{figure}
In other words return values with a context, and we do not to reinvent wheel, because Monads does exactly that, and the Gen Monad returned by \verb|arbitrary| is an example of one.
In practice we do not need to call \verb|generate| explicitly, this done by the \verb|quickCheck| which uses a supplied generator for the type, that matches input to the property that should hold. If have to use a custom generator like in \ref{lst:GenDef} or \ref{lst:genComplex}, you need to pass in the your generator as first parameter to \verb|forAll| function.
\begin{hscode}
    forAll :: (Testable prop) => Gen a -> (a -> prop) -> Property
    prop_winner_diceRoll12_alwaysHouse = 
        forAll (diceRoller 12) \$ \roll -> houseWins roll == "House Wins"
\end{hscode}
Perhaps something on size?

\subsection{\acrlong{ltl}}
Despite the usefulness of testing for equality, some properties such as: the stream elements are always positive; the stream is monotonic non-decreasing; the stream elements will eventually reach a certain value etc. are infeasible to test with only equality. To test such we need a language to specify streams in a flexible way precise enough for testing. One such language is \acrfull{ltl}.
\acrshort{ltl} is best thought of as a time dependent superset of propositional logic. \acrshort{ltl} has the logical operators from propositional logic and modalities, which describes temporal behavior.

\acrshort{ltl} models the world much more precise for the same reasons as signal does: Values of observations almost always depends on time. Atomic propositions like: "The vehicle is moving"; "we are heading in the right direction"; "We receive sensor readings". Are written in present tense, but the truth value of these vary with time. Such atomic propositions are typical examples of elements in \verb|Atoms| which the syntax of \acrshort{ltl} build on.

\subsubsection{Syntax}
The syntax of a formula in \acrshort{ltl} can be defined recursively with the following:
\begin{definition}
Syntax of \acrshort{ltl}
\label{def:formula}
\begin{itemize}
    \item if $ p \in \texttt{Atoms} \cup {\top, \bot} $ then $p$ is an \acrshort{ltl} formula
    \item if $\phi$ $\psi$ are \acrshort{ltl} formulas then $(\sim \phi,) (\psi \vee \phi), (\mathbf{X} \phi), (\psi \mathbf{U} \phi)$ are \acrshort{ltl} formulas
\end{itemize}
\end{definition}
These operators are adequate to form a basis for many more operators, some of which will be introduced in the next section.
According to such syntax $((\mathbf{X}\phi) \vee \psi)$ is a formula. However to reduce parentheses yet still preserve ambiguity the following convention applies: The unary connectives binds the strongest; followed by the binary connectives. The convention allows for simplifications such as
$$((\mathbf{X}\phi) \vee \psi) \equiv \mathbf{X}\phi \vee \psi$$

\subsubsection{Semantics}
Formally \acrshort{ltl} can verify systems that can be modelled as transitions systems. A transition can be represented by a directed graph where each node is a state, and each edge is a transition. Each state can can be given to a labelling function $L: S \rightarrow \mathcal{P}(\texttt{Atoms})$ which takes a state and returns the set of true propositions $p in \texttt{Atoms}$ for that state. A path is an infinite sequence of transitions such as $\pi: s_1 \rightarrow s_2 \rightarrow s_3 \rightarrow s_4 \rightarrow \dots $. 
The infinity requirement of a path leads to the requirement that no state can 'dead-lock', because these deadlocks can would produces finite streams. 
But as the digraph representation hints such a system can contain many different paths and $\pi: s_1 \rightarrow s_2 \rightarrow s_1 \rightarrow s_2 \rightarrow  \dots $ could be a different path.
Luckily for us, the paths we describe comes from streams, where each state appears chronologically and is deterministic. Hence we only to consider a single path. However, we need a definition \ref{def:LTLSemantics} for deciding whether $\pi$ satisfies an \acrshort{ltl}-formula, which we denote as $\pi \vDash \phi$. 
To distinguish temporal operators from propositional ones, the latter is written in words. 

\begin{definition}
\label{def:LTLSemantics}
Semantics of \acrshort{ltl}
\begin{enumerate}
    \item $\pi \vDash \top$
    \item $\pi \nvDash \bot$
    \item $\pi \vDash p \Leftrightarrow p \in L(s_1) $
    \item $\pi \vDash \sim \phi \Leftrightarrow \pi \nvDash \phi$
    \item $\pi \vDash \phi \vee \psi \Leftrightarrow \pi \vDash \phi\text{ or }\pi \vDash \psi$
    \item $\pi \vDash \mathbf{X} \phi \Leftrightarrow \pi^2 \vDash \phi$
    \item $\pi \vDash \phi \mathbf{U} \psi \Leftrightarrow \exists i\in \mathbb{N}.\pi^i \vDash \psi \text{ and } \forall j.  \pi^j \vDash \phi \text{ and } j < i$
\end{enumerate}
\end{definition}
Consider the following example suppose we have a path $\kappa: 1 \rightarrow 2 \rightarrow 3 \rightarrow \dots$   
where each state is an integer. We also have a labelling function $K(s) = \mathcal{P}({q_1})$ where $q_1$ is the proposition \emph{the state is 1}. We then say that $\kappa \vDash q_e$ because $q_e \in K(1)$.
We could also so ask model the property that the next to states are odd numbers, by the formula $\phi = q_{odd} \wedge \mathbf{X} q_{odd}$ where $K(s) = \mathcal{P}({q_{odd}})$ and $q_{odd}$ is the proposition \emph{the state is odd}.
By working our way through the formula with definition \ref{def:LTLSemantics}, we get
\begin{align*}
                            & \kappa \vDash \phi \\
    \Leftrightarrow \quad   & \kappa \vDash q_{odd} \wedge \mathbf{X} q_{odd} \\
    \Rightarrow     \quad   & \kappa \vDash \mathbf{X} q_{odd} \\ 
    \Leftrightarrow \quad   & \kappa^2 \vDash q_{odd} \\ 
    \Leftrightarrow \quad   & p_{odd} \in K(2)
\end{align*}  
which is contradiction because 2 is not an odd number, an hence $\kappa \nvDash \phi$.
\acrshort{ltl} is complete for our purpose, since $\forall \pi . \exists \phi . \pi \vDash \phi$. This is good feature in our case, however the formula might be infinite. An example is a formula matches a stream of digits from an irrational number.

With these semantics in place we can start to model stream properties properties like
\begin{itemize}
    \item The output will start with a "Bang!"
    \item The output will eventually reach some value $a$
    \item The output will always be an odd number
\end{itemize}
